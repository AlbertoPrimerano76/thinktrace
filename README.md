# ğŸ¤– ThinkTrace MCP Agentic Framework

Welcome to the **ThinkTrace Modular Agentic Reasoning System**, a powerful AI infrastructure for **structured reasoning**, **dynamic tool use**, and **explainable LLM-based workflows** using **Ollama**, **MCP**, and optionally **Gradio** for UI.

Built for speed, transparency, and modularity.

---

## ğŸ§  What It Does

- Dynamically **suggests and invokes tools only when necessary**.
- Produces **structured reasoning steps** (intent, dependencies, final output).
- Explains each step via **Rich console tree** or **Gradio chat**.
- Wraps **MCP-compatible tools** into Ollama/LLM agents.
- Easily extended with Pydantic, CrewAI, or LangGraph agents.

---

## ğŸ—‚ï¸ Project Structure

thinktrace/ â”œâ”€â”€ core/ â”‚ â”œâ”€â”€ config_manager.py # Loads settings from .env â”‚ â”œâ”€â”€ logger_manager.py # Rich-based logging (console + file) â”‚ â”œâ”€â”€ tree_renderer.py # Pretty tree output for reasoning steps â”‚ â””â”€â”€ mcp_server.py # Server-side lifecycle â”‚ â”œâ”€â”€ tools/ â”‚ â””â”€â”€ reasoning_engine.py # LLM reasoning + step execution (Ollama) â”‚ â”œâ”€â”€ ui/ â”‚ â””â”€â”€ ui_gradio.py # Gradio-based chat frontend â”‚ â”œâ”€â”€ ai/ â”‚ â””â”€â”€ ollama_agent.py # Ollama agent + tool resolver â”‚ â”œâ”€â”€ main.py # Gradio/CLI entry point â”œâ”€â”€ .env # Environment variables â”œâ”€â”€ requirements.txt


---

## âš™ï¸ Setup & Activation (using [uv](https://github.com/astral-sh/uv))

